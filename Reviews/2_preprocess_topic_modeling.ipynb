{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_words = ['i', 'me', 'my', 'mine', 'myself']\n",
    "we_words = ['we', 'us', 'our', 'ours', 'ourselves']\n",
    "they_words = ['they', 'them', 'their', 'theirs', 'theirselves']\n",
    "def count_we_i(df):\n",
    "    we = sum([1 for t in df['pros_toks'] if t in we_words])\n",
    "    we += sum([1 for t in df['cons_toks'] if t in we_words])\n",
    "    i = sum([1 for t in df['pros_toks'] if t in i_words])\n",
    "    i += sum([1 for t in df['cons_toks'] if t in i_words])\n",
    "    log_we_i = np.log(we/i) if i > 0 and we > 0 else np.nan\n",
    "    return log_we_i\n",
    "\n",
    "def count_we_they(df):\n",
    "    we = sum([1 for t in df['pros_toks'] if t in we_words])\n",
    "    we += sum([1 for t in df['cons_toks'] if t in we_words])\n",
    "    they = sum([1 for t in df['pros_toks'] if t in they_words])\n",
    "    they += sum([1 for t in df['cons_toks'] if t in they_words])\n",
    "    log_we_they = np.log(we/they) if we > 0 and they > 0 else np.nan\n",
    "    return log_we_they\n",
    "\n",
    "def count(df, words, colname):\n",
    "    return sum([1 for t in df[colname] if t in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import contractions\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "tokenizer = TweetTokenizer()\n",
    "survey_hr_df = pd.read_csv('~/Documents/CompCulture/spacespace/Coco/analyses_data/preprocessed_survey_hr.csv')\n",
    "survey_text_df = survey_hr_df.dropna(subset=['pros', 'cons', 'story']).astype({'pros':'str',\n",
    "                             'cons':'str',\n",
    "                             'story':'str'})\n",
    "\n",
    "survey_text_df['disengagement_3'] = 4 - survey_text_df['disengagement_3']\n",
    "survey_text_df['exhaustion_2'] = 4 - survey_text_df['exhaustion_2']\n",
    "survey_text_df['disengagement'] = survey_text_df[['disengagement_1', 'disengagement_2', 'disengagement_3']].mean(axis=1)\n",
    "survey_text_df['exhaustion'] = survey_text_df[['exhaustion_1', 'exhaustion_2', 'exhaustion_3']].mean(axis=1)\n",
    "survey_text_df['burnout'] = survey_text_df[['disengagement', 'exhaustion']].mean(axis=1)\n",
    "survey_text_df['race'] = survey_text_df['Race'].apply(lambda x : 'Other' if x in ['Black or African American', 'Missing', 'Native Hawaiian or Other Pacific Islander'] else x)\n",
    "survey_text_df = survey_text_df.drop(columns=['ResponseId', 'LocationLatitude', 'LocationLongitude', \"LINK\", \"Race\"]\n",
    "                    + [\"mael_\"+str(i) for i in range(1, 7)]\n",
    "                    + [\"disengagement_\"+str(i) for i in range(1, 4)]\n",
    "                    + [\"exhaustion_\"+str(i) for i in range(1, 4)])\n",
    "\n",
    "stop_words = STOP_WORDS\n",
    "# edited to be consistent with stop words used in processing glassdoor reviews\n",
    "custom_stop_words = ['people', 'collabera', 'employee', 'employees', 'collabera\\'s', 'work', 'working', 'company', 'great', 'good', 'lot', 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa']\n",
    "\n",
    "stop_words = set(list(stop_words) + custom_stop_words)\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "# getting rid of these tokens that are not included in the pre-defined punctuation list\n",
    "# no better lists existing\n",
    "punctuation = string.punctuation + '–...…’“”'\n",
    "survey_text_df['low_quality_response'] = np.where((survey_text_df['pros'] == survey_text_df['cons']) |\n",
    "                                                  (survey_text_df['cons'] == survey_text_df['story']) | \n",
    "                                                  (survey_text_df['pros'] == survey_text_df['story']),\n",
    "                                                  1, 0)\n",
    "\n",
    "survey_text_df['pros_toks'] = survey_text_df['pros'].apply(contractions.fix).str.lower().apply(lambda x: x.replace('.',' ')).apply(tokenizer.tokenize)\n",
    "survey_text_df['cons_toks'] = survey_text_df['cons'].apply(contractions.fix).str.lower().apply(lambda x: x.replace('.',' ')).apply(tokenizer.tokenize)\n",
    "survey_text_df['story_toks'] = survey_text_df['story'].apply(contractions.fix).str.lower().apply(lambda x: x.replace('.',' ')).apply(tokenizer.tokenize)\n",
    "\n",
    "survey_text_df['pros_we'] = survey_text_df.apply(count, args=(we_words, 'pros_toks',), axis=1)\n",
    "survey_text_df['pros_i'] = survey_text_df.apply(count, args=(i_words, 'pros_toks'), axis=1)\n",
    "survey_text_df['pros_they'] = survey_text_df.apply(count, args=(they_words, 'pros_toks'), axis=1)\n",
    "survey_text_df['cons_we'] = survey_text_df.apply(count, args=(we_words, 'cons_toks'), axis=1)\n",
    "survey_text_df['cons_i'] = survey_text_df.apply(count, args=(i_words, 'cons_toks'), axis=1)\n",
    "survey_text_df['cons_they'] = survey_text_df.apply(count, args=(they_words, 'cons_toks'), axis=1)\n",
    "survey_text_df['story_we'] = survey_text_df.apply(count, args=(we_words, 'story_toks'), axis=1)\n",
    "survey_text_df['story_i'] = survey_text_df.apply(count, args=(i_words, 'story_toks'), axis=1)\n",
    "survey_text_df['story_they'] = survey_text_df.apply(count, args=(they_words, 'story_toks'), axis=1)\n",
    "\n",
    "# removing bullet points and numbers\n",
    "re_number = r\"[0-9]+(\\.)?\"\n",
    "# doing this in two batches so we can get the correct count on pronouns first\n",
    "survey_text_df['pros_toks'] = survey_text_df['pros_toks'].apply(\n",
    "    lambda toks : [lemmatizer.lemmatize(t) for t in toks\n",
    "                   if t not in punctuation and t not in stop_words and re.match(re_number, t) is None])\n",
    "survey_text_df['cons_toks'] = survey_text_df['cons_toks'].apply(\n",
    "    lambda toks : [lemmatizer.lemmatize(t) for t in toks\n",
    "                   if t not in punctuation and t not in stop_words and re.match(re_number, t) is None])\n",
    "survey_text_df['story_toks'] = survey_text_df['story_toks'].apply(\n",
    "    lambda toks : [lemmatizer.lemmatize(t) for t in toks\n",
    "                   if t not in punctuation and t not in stop_words and re.match(re_number, t) is None])\n",
    "\n",
    "# note that given that this cleaned version does not retain stop words, any algorithm that needs \n",
    "# stop words, e.g., glove or sentence embeddings, should not use these columns defined as such\n",
    "survey_text_df['pros_cleaned'] = survey_text_df['pros_toks'].apply(' '.join)\n",
    "survey_text_df['cons_cleaned'] = survey_text_df['cons_toks'].apply(' '.join)\n",
    "survey_text_df['story_cleaned'] = survey_text_df['story_toks'].apply(' '.join)\n",
    "\n",
    "survey_text_df['pros_toks_len'] = survey_text_df['pros_toks'].apply(len)\n",
    "survey_text_df['cons_toks_len'] = survey_text_df['cons_toks'].apply(len)\n",
    "survey_text_df['story_toks_len'] = survey_text_df['story_toks'].apply(len)\n",
    "\n",
    "survey_text_df['glassdoor_toks'] = survey_text_df.apply(lambda row : row['pros_toks'] + row['cons_toks'], axis=1)\n",
    "survey_text_df['glassdoor_cleaned'] = survey_text_df['glassdoor_toks'].apply(' '.join)\n",
    "survey_text_df['glassdoor_toks_len'] = survey_text_df['glassdoor_toks'].apply(len)\n",
    "\n",
    "survey_text_df['low_quality_pros'] = survey_text_df.apply(lambda row : 1 if (row['pros_toks_len'] < 3) else row['low_quality_response'], axis=1)\n",
    "survey_text_df['low_quality_cons'] = survey_text_df.apply(lambda row : 1 if (row['cons_toks_len'] < 3) else row['low_quality_response'], axis=1)\n",
    "survey_text_df['low_quality_story'] = survey_text_df.apply(lambda row : 1 if (row['story_toks_len'] < 3) else row['low_quality_response'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_text_df.to_csv('~/Documents/CompCulture/spacespace/Coco/analyses_data/survey_hr_topic_modeling.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
