{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Usage:\n",
    "    3b_output_alternative_measuress.py test|actual\n",
    "If a Negative Dimension Error occurs, check to see if there are empty embeddings\n",
    "Two types of results are currently computed\n",
    "1) Projections\n",
    "2) Raw count frequencies\n",
    "\"\"\"\n",
    "import os\n",
    "import sys\n",
    "import multiprocessing\n",
    "from collections import defaultdict, Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.matutils import cossim, any2sparse\n",
    "from utils import *\n",
    "import re\n",
    "import random\n",
    "from statistics import mean \n",
    "import ujson as json\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "embedding_dim = 50\n",
    "mincount = 150\n",
    "home_dir = \"/ifs/projects/amirgo-identification/\"\n",
    "email_dir = os.path.join(home_dir, \"email_data/\")\n",
    "mittens_dir = os.path.join(home_dir, \"mittens\")\n",
    "utils_dir = os.path.join(mittens_dir, \"utils\")\n",
    "embeddings_dir = os.path.join(mittens_dir, \"embeddings_{}d_mincount{}\".format(embedding_dim, mincount))\n",
    "email_file = os.path.join(email_dir, 'MessagesHashed.jsonl')\n",
    "users_file = os.path.join(email_dir, 'Users.json')\n",
    "activity_file = os.path.join(email_dir, 'Activities.json')\n",
    "survey_dir = os.path.join(home_dir, \"survey_hr_data\")\n",
    "user_qualtrics_file = os.path.join(survey_dir, \"UsersQualtrics.csv\")\n",
    "perf_percentage = os.path.join(survey_dir, \"perf_rating_percentages.csv\")\n",
    "perf_likert = os.path.join(survey_dir, \"perf_rating_likert.csv\")\n",
    "\n",
    "analyses_data_dir = \"/ifs/gsb/amirgo/spacespace/spacespace/Coco/analyses_data/\"\n",
    "survey_filename = os.path.join(analyses_data_dir, \"preprocessed_survey_hr.csv\")\n",
    "company_embeddings_filename = \"/ifs/gsb/amirgo/spacespace/spacespace/Coco/Embed/GloVe-master/vectors_{}d.txt\".format(embedding_dim)\n",
    "\n",
    "tmp_dir = os.path.join(mittens_dir, \"tmp\")\n",
    "output_dir = os.path.join(home_dir, \"email_idtf_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_colname, quarter_colname = 'year', 'quarter'\n",
    "hash2word = {\n",
    "    '09f83385': 'mine', '20019fa4': 'i', '20b60145': 'us', '28969cb1': 'them', '3828d3d2': 'me', '4dd6d391': 'their', '5b4e27db': 'my',\n",
    "    '64a505fc': 'ourselves', '6935bb23': 'ours', '6f75419e': 'myself', '86df0c8d': 'themselves', 'a7383e72': 'we', 'a9193217': 'theirs', 'b72a9dd7': 'our', 'fd0ccf1c': 'they', \n",
    "    'ce696289': 'home', 'b95eb14b': 'attached', '267430a0': 'good', '294fa7d1': 'collabera', '974811d0': 'pay', 'edbf568e': 'work', 'b71be0e8': 'team', '4c088971': 'great',\n",
    "    'c74560f9': 'best', 'f18e6868': 'different', '1f4d7738': 'group', '255ddfcd': 'glad', 'aa829423': 'included', '17e1378b': 'money', '454ea538': 'salary', '311b8ad0': 'community',\n",
    "    '3b75b927': 'happy', '9324aa22': 'organized', '63b8b7ea': 'bad', '643ce56f': 'responsive', 'f4732b84': 'enthusiastic', '2e32c475': 'competitive', 'b9625ccf': 'family',\n",
    "    '900c73ff': 'unresponsive', 'cfe1bd08': 'income', '223deabb': 'worst', 'fa81b32a': 'pride', '1455e3bd': 'passionate', '9582e03b': 'awful', 'd9f0fe6c': 'promotion',\n",
    "    'c40b5da1': 'excluded', 'cf9cb85a': 'ambitious', 'a0cb3a2b': 'sad', '8a4e04bd': 'honor', 'cafaa726': 'belong', '24cb6fe3': 'shame', 'b92208fc': 'disciplined', '68e0c9c9': 'undisciplined',\n",
    "    '81bcf2f5': 'receptive', '8ca67680': 'disorganized', 'd22e4710': 'bitter', 'bf4db4c4': 'unenthusiastic', '8602bd25': 'dignity', '822f792d': 'detached', 'a7ca40f1': 'humiliation',\n",
    "    '7911da73': 'noncompetitive', '627fcac3': 'dishonor', '84cadff4': 'unreceptive', '07ca39d6': 'lazy', '95a160e0': 'indifferent', '10a4d7ee': 'apathetic'}\n",
    "word2hash = {v:k for k, v in hash2word.items()}\n",
    "pronouns = ['i', 'me', 'my', 'mine', 'myself', 'we', 'us', 'our', 'ours', 'ourselves']\n",
    "single_pronouns = ['i', 'we']\n",
    "i_index, we_index = 0, 5\n",
    "hash_pronouns = [word2hash[p] for p in pronouns]\n",
    "hash_single_pronouns = [word2hash[p] for p in single_pronouns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dimension(words_start, words_end):\n",
    "    \"\"\"\n",
    "    This method builds a dimension defined by words at separate end of a dimension.\n",
    "    Multiple methods exist in previous literature when building such a dimension.\n",
    "    1) Kozlowski et al. (2019) averages across differences between different word pairs, noted to be interchangeable with averaging words on each side of the dimension and\n",
    "    then taking the difference between averages. They are empirically verified to be identical.\n",
    "    2) Bolukbasi et al. (2016) defines gender direction using a simple difference between man and woman in the corresponding tutorial. In the same tutorial, \n",
    "    racial direction is defined as difference between two clusters of words that are each sum of the embeddings of its corresponding dimensions\n",
    "    normalized by the L2 norm. Wang et al. (2020) note that normalization is unnecessary. If unnormalized, this method should be equivalent to #3.\n",
    "    3) Bolukbasi et al. (2016) defines gender direction also by taking the differences across multiple pairs, doing PCA on these differences, and \n",
    "    taking the first component as the gender direction.\n",
    "    Parameter\n",
    "    ---------\n",
    "    words_start : list\n",
    "        List of hashed words at the positive end of the dimension, where positive implies more likely to affect identification positively\n",
    "    words_end: list\n",
    "        List of hashed words at the other end of dimension\n",
    "    Returns\n",
    "    -------\n",
    "    (mean_dim, pca_dimension) : 2-tuple of numpy vector\n",
    "        Two vector that represents the dimension of interest calculated using method #1 and #3.\n",
    "    \"\"\"\n",
    "    assert len(words_start) == len(words_end)\n",
    "    differences = [(np.array(words_start[i]) - np.array(words_end[i])) for i in range(len(words_start)) if not np.isnan(words_start[i]).any() and not np.isnan(words_end[i]).any()]\n",
    "    mean_dim = np.array(differences).mean(axis=0)\n",
    "    pca_dim = doPCA(words_start, words_end)\n",
    "    if project(words_start[0], pca_dim) < 0:\n",
    "        # convention used in the current script is that words_start should represent the positive dimension\n",
    "        pca_dim = pca_dim * -1\n",
    "    return (mean_dim, pca_dim)\n",
    "\n",
    "\n",
    "def build_all_dimensions():\n",
    "    \"\"\"\n",
    "    Returns a dictionary that matches dimension name to a 2-tuple of dimensions, where eacb dimension is represented using a numpy vector.\n",
    "    \"\"\"\n",
    "    name2hashes = {'family_dim': ([word2hash[word] for word in ['family', 'home', 'community', 'team']],\n",
    "        [word2hash[word] for word in ['money', 'pay', 'salary', 'income']]),\n",
    "        'valence_dim': ([word2hash[word] for word in [\"good\", \"great\", \"best\"]],\n",
    "            [word2hash[word] for word in [\"bad\", \"awful\", \"worst\"]]),\n",
    "        'belonging_dim': ([word2hash[word] for word in ['included', 'attached']],\n",
    "            [word2hash[word] for word in ['excluded', 'detached']]),\n",
    "        'pride_dim': ([word2hash[word] for word in [\"pride\", \"dignity\", \"honor\"]],\n",
    "            [word2hash[word] for word in [\"shame\", \"humiliation\", \"dishonor\"]]),\n",
    "        'passionate_dim': ([word2hash[word] for word in [\"passionate\"]],\n",
    "            [word2hash[word] for word in [\"indifferent\"]]),\n",
    "        'competitive_dim': ([word2hash[word] for word in [\"competitive\"]], # noncompetitive is not included in GloVe, thus this word-pair is restricted to one word\n",
    "            [word2hash[word] for word in [\"lazy\"]]),\n",
    "        'responsive_dim': ([word2hash[word] for word in [\"responsive\"]],\n",
    "            [word2hash[word] for word in [\"unresponsive\"]]),\n",
    "        'disciplined_dim': ([word2hash[word] for word in [\"disciplined\"]],\n",
    "            [word2hash[word] for word in [\"undisciplined\"]]),\n",
    "        'we_dim': (hash_pronouns[we_index:], hash_pronouns[i_index:we_index])}\n",
    "    dims = {k : build_dimension([company_model[h] for h in hashes[0]], [company_model[h] for h in hashes[1]]) for k, hashes in name2hashes.items()}\n",
    "    return dims\n",
    "\n",
    "\n",
    "def doPCA(words_start, words_end):\n",
    "    \"\"\"\n",
    "    Performs PCA on differences between pairs of words and returns the first component\n",
    "    Based on function doPCA in Bolukbasi et al. (2016) source code at https://github.com/tolga-b/debiaswe/blob/master/debiaswe/we.py\n",
    "    Parameter\n",
    "    ---------\n",
    "    words_start : list\n",
    "        List of hashed words at one end of interested dimension\n",
    "    words_end: list\n",
    "        List of hashed words at the other end of dimension\n",
    "    Returns\n",
    "    -------\n",
    "    ndarray\n",
    "        First component of PCA of differences between pairs of words\n",
    "    \"\"\"\n",
    "    matrix = []\n",
    "    for i in range(len(words_start)):\n",
    "        center = (words_start[i] + words_end[i])/2\n",
    "        matrix.append(words_end[i] - center)\n",
    "        matrix.append(words_start[i] - center)\n",
    "    matrix = np.array(matrix)\n",
    "    # cannot have more components than the number of samples\n",
    "    num_components = len(words_start)*2\n",
    "    pca = PCA(n_components = num_components)\n",
    "    pca.fit(matrix)\n",
    "    return pca.components_[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building company model at 2021-01-24 12:34:37.995404.\n"
     ]
    }
   ],
   "source": [
    "sys.stderr.write(\"Building company model at %s.\\n\" % datetime.now())    \n",
    "tmp_mittens = os.path.join(tmp_dir, \"mittens_embeddings_all_word2vec.txt\")\n",
    "word2vec_mittens_file = get_tmpfile(tmp_mittens)\n",
    "glove2word2vec(company_embeddings_filename, word2vec_mittens_file)\n",
    "company_model = KeyedVectors.load_word2vec_format(word2vec_mittens_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "name2dims = build_all_dimensions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = extract_company_embedding(company_embeddings_filename, tmp_dir, name2hashes['belonging_dim'][0])\n",
    "projs = [mean([project(v, dims[d][i]) for v in vectors]) for d in ['family_dim', 'belonging_dim'] for i in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2499301"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project(company_model[word2hash['belong']], name2dims['we_dim'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/jupyter/hub/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.22347 , -0.07838 , -0.156123, -0.631888, -1.007747,  0.772272,\n",
       "       -0.313167,  1.189707,  0.213136,  0.686144, -0.148634,  0.280543,\n",
       "       -0.905314,  0.104314,  0.530036, -1.37175 , -0.530577,  0.383711,\n",
       "       -0.367105,  0.852505,  0.038253, -0.347726, -0.373564, -1.106648,\n",
       "       -1.222034, -1.057687, -0.721559, -0.649887,  0.391958,  0.967776,\n",
       "        1.256379, -0.173398, -1.677725, -1.276426, -0.438065, -1.254676,\n",
       "        0.617702, -1.825377,  0.48235 , -0.734699,  0.955322,  1.889708,\n",
       "       -1.071647, -0.34003 ,  1.383348,  0.571729,  0.295111, -1.366562,\n",
       "       -0.222192,  1.937998], dtype=float32)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['81bcf2f5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = [i for i in range(10)]\n",
    "raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "tally=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in raw:\n",
    "    tally=(tally+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_dims = ['i_we', 'family', 'belonging', \"pride\", \"valence\"]\n",
    "post = ['_mean_proj', '_pca_proj']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['num_i_words', 'num_we_words'] + [d+p for d in general_dims for p in post]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.23779483139514923,\n",
       " 0.1259683072566986,\n",
       " 2.5891361236572266,\n",
       " 2.673535108566284,\n",
       " 1.373583436012268,\n",
       " 1.3155254125595093,\n",
       " 2.7780447006225586,\n",
       " 2.7770185470581055,\n",
       " 2.6363561153411865,\n",
       " 2.64739727973938]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toks = ['311b8ad0']\n",
    "relevant_dims = ['we_dim', 'family_dim', 'belonging_dim', 'pride_dim', 'valence_dim']\n",
    "[sum([project(model[t], dims[d][i]) for t in toks if t in model.vocab]) for d in relevant_dims for i in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.467495, -0.889436, -0.919916, -0.471172,  0.732633, -0.018749,\n",
       "         1.488797, -0.198742,  0.533597, -0.609984, -1.079914,  0.27499 ,\n",
       "         0.352249,  0.343783, -1.058495,  0.346726, -0.856571,  0.706777,\n",
       "         1.158149,  1.287304,  0.392948, -1.009327, -0.24711 ,  0.466427,\n",
       "         0.381957, -0.69002 ,  0.157154,  0.802895,  0.559304, -0.007793,\n",
       "        -0.615379, -0.621199, -1.14191 ,  0.529251,  0.982216, -0.463823,\n",
       "         1.05352 , -1.32042 , -0.891966, -0.955758,  0.281336, -0.308861,\n",
       "         0.617961, -0.129833, -0.214225, -0.394984, -0.932921,  0.770892,\n",
       "        -0.175157,  1.052361], dtype=float32),\n",
       " array([ 0.804172, -0.161137, -0.113271, -0.102526, -0.832099, -0.463523,\n",
       "        -0.18788 , -0.214295,  0.853695,  0.06118 ,  0.263742, -0.020479,\n",
       "         0.175829,  0.13101 , -0.172181, -0.033704,  0.084849,  0.483015,\n",
       "        -0.119548, -0.056045, -0.739555,  0.149796, -0.179506, -0.048233,\n",
       "         0.030957,  0.587561, -0.43645 ,  0.136448, -0.287946,  0.171395,\n",
       "        -2.779449, -0.912154, -1.943291, -0.318882,  0.587618,  0.394159,\n",
       "         0.488005,  0.520454, -0.049413, -0.436258, -0.971061, -0.536185,\n",
       "        -0.779467, -0.075844,  0.353375, -0.106121,  0.169127, -0.641698,\n",
       "         0.249655, -0.056826], dtype=float32),\n",
       " array([ 0.65573 ,  0.089243, -1.358492, -0.231684,  0.197579, -1.030177,\n",
       "         0.137281,  0.494203, -0.263403, -0.551208, -0.463606,  0.936454,\n",
       "         0.661726, -0.220496, -0.315879,  1.342681, -0.68706 ,  0.239598,\n",
       "         0.366748, -0.402538,  0.009159,  0.384433,  0.470517,  1.569752,\n",
       "        -0.156634, -0.429706, -0.165341, -0.757246, -0.192683,  0.589609,\n",
       "        -4.850505, -0.062483, -1.410007,  0.263091,  0.352303,  0.587922,\n",
       "         0.395739,  0.378821,  0.586983,  0.22184 , -1.368768,  0.143974,\n",
       "        -1.141131, -0.105404,  0.557112, -0.606101,  0.608141, -0.114022,\n",
       "         0.557546,  0.450349], dtype=float32)]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ujson as json\n",
    "\n",
    "total_emails = 0\n",
    "non_english = 0\n",
    "english = 0\n",
    "ling_thres = 0.9\n",
    "\n",
    "email_dir = \"/ifs/projects/amirgo-identification/email_data/\"\n",
    "out_dir = \"/ifs/gsb/amirgo/spacespace/spacespace/Coco/Embed/GloVe-master/\"\n",
    "email_file = os.path.join(email_dir, 'MessagesHashed.jsonl')\n",
    "activity_file = os.path.join(email_dir, 'Activities.json')\n",
    "\n",
    "def read_emails(in_file, target_users):\n",
    "    sid2activity = {}\n",
    "    with open(activity_file, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            activity = json.loads(line)\n",
    "            if activity['UserId'] in target_users:\n",
    "                sid2activity[activity['MailSummarySid']] = activity\n",
    "    target_sids = sid2activity.keys()\n",
    "    \n",
    "    with open(in_file, encoding='utf-8') as f:            \n",
    "        for i, line in enumerate(f):\n",
    "            if i % 1000000 == 0:\n",
    "                print(\"Processed {} emails\".format(i))\n",
    "            global total_emails, english, non_english\n",
    "            total_emails += 1\n",
    "            email = json.loads(line)\n",
    "            if email['sid'] in target_sids:\n",
    "                lang = email['l']\n",
    "                if len(body) > 0:\n",
    "                    # original - if lang[0] == \"__label__en\" and (lang[1] > 0.5 or len(email['liwc']) > 0):\n",
    "                    if lang[0] == \"__label__en\" and lang[1] > ling_thres:\n",
    "                        english += 1\n",
    "                    elif len(lang[0]) > 0:\n",
    "                        non_english += 1\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_file = 'target_users.txt'\n",
    "with open(target_file, \"r\") as file:\n",
    "    userids = []\n",
    "    for line in file:\n",
    "        userids.append(line.strip()) # removing newline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 emails\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'body' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-8073bc038a95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mread_emails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memail_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-00c757f36182>\u001b[0m in \u001b[0;36mread_emails\u001b[0;34m(in_file, target_users)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0memail\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sid'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtarget_sids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0mlang\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memail\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'l'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m                     \u001b[0;31m# original - if lang[0] == \"__label__en\" and (lang[1] > 0.5 or len(email['liwc']) > 0):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__label__en\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mling_thres\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'body' is not defined"
     ]
    }
   ],
   "source": [
    "read_emails(email_file, userids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
