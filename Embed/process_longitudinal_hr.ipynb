{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data as pandas df\n",
    "# create new dictionary using user and timekey as keys\n",
    "# give empty row to every user and timekey combination\n",
    "# list time keys as 2017Q1 to 2020Q3\n",
    "# sort by user and then sort by action date\n",
    "# for each record\n",
    "    # grab action date\n",
    "    # calculate quarter of action date\n",
    "    # walk backwards one quarter, add to dictionary and fill in all fields\n",
    "    # add to dictionary and fill in all fields for current quarter\n",
    "# convert dictionary to pandas\n",
    "# fill forwards and fill backwards\n",
    "# ensure no data exists past termination date\n",
    "# take cross-sectional hr data\n",
    "# select users who are not in the longitudinal data\n",
    "# replicate record for every quarter\n",
    "# add them into longitudinal data\n",
    "# add gender race and date of birth in\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "from datetime import date\n",
    "\n",
    "data_dir = \"/Users/Lara/Documents/Stanford/Research/Collabera/Data\"\n",
    "# this version contains race, age, and work country that Collabera_HR.csv does not contain\n",
    "cs_hr_path = os.path.join(data_dir, \"Collabera_HR.csv\")\n",
    "cs_perf_hr_path = os.path.join(data_dir, \"Collabera_HR_Perf.csv\")\n",
    "user_qualtrics_path = os.path.join(data_dir, \"qualtrics/UsersQualtrics.csv\")\n",
    "promotion_path = os.path.join(data_dir, \"promotion_data.csv\")\n",
    "transfer_path = os.path.join(data_dir, \"transfer_data.csv\")\n",
    "perf_percentage_path = os.path.join(data_dir, \"perf_rating_percentages.csv\")\n",
    "perf_rating_path = os.path.join(data_dir, \"perf_rating_likert.csv\")\n",
    "\n",
    "timekeys = [str(year)+\"Q\"+str(quarter) for year in range(2017, 2021) for quarter in range(1,5)]\n",
    "timekeys.remove(\"2020Q4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date2quarter(date):\n",
    "    \"\"\"\n",
    "    Return quarter of date in string\n",
    "    \"\"\"\n",
    "    year, month = 0, 0\n",
    "    date_obj = datetime.strptime(date, '%d-%b-%y')\n",
    "    year = date_obj.year\n",
    "    month = date_obj.month\n",
    "    quarter = ((int(month)-1) // 3) + 1\n",
    "    timekey = str(year) + 'Q' + str(quarter)\n",
    "    return timekey\n",
    "\n",
    "def calc_prev_quarter(quarter):\n",
    "    \"\"\"\n",
    "    Return the quarter that immediately precedes current quarter\n",
    "    \"\"\"\n",
    "    q = int(quarter[-1])\n",
    "    if q > 1:\n",
    "        prev_quarter = quarter[:-1]+str(q-1)\n",
    "    else:\n",
    "        year = int(quarter[0:4])\n",
    "        prev_quarter = str(year-1)+'Q4'\n",
    "    return prev_quarter\n",
    "\n",
    "def calc_tenure(hire_date, quarter):\n",
    "    \"\"\"\n",
    "    Calculate how many days have elapsed between hire date and the end of quarter\n",
    "    \"\"\"\n",
    "    hire_obj = datetime.strptime(hire_date, '%d-%b-%y')\n",
    "    curr_year = int(quarter[0:4])\n",
    "    curr_month = 3*int(quarter[-1])\n",
    "    curr_day = calendar.monthrange(curr_year, curr_month)[-1]\n",
    "    curr_date_obj = datetime(curr_year, curr_month, curr_day)\n",
    "    return (curr_date_obj - hire_obj).days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Longitudinal Data Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_header = ['year', 'tenure', 'job_title', 'division', 'department',\n",
    "          'function', 'work_location', 'work_state', 'work_country', 'legal_entity',\n",
    "               'exit', 'exit_reason', 'promotion', 'salary_increase', 'demotion']\n",
    "users = cs_df['UID'].to_list()\n",
    "user_quarter2values = dict()\n",
    "rows = list()\n",
    "for u in users:\n",
    "    for q in timekeys:\n",
    "        user_quarter2values[(u, q)] = [int(q[0:4])] + [np.nan for i in range(9)] + [0, np.nan, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Promotion Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "promotion_df = pd.read_csv(promotion_path)\n",
    "\n",
    "promotion_df = promotion_df.drop(['PERSON ID', 'PERSON NUMBER', 'DOJ', \"LINK\"], axis=1)\n",
    "names = promotion_df.columns.tolist()\n",
    "promotion_df = promotion_df[['UID']+names[:-1]]\n",
    "promotion_df['total_finite_fields'] = promotion_df.count(axis=1)\n",
    "promotion_df['total_distinct_fields'] = promotion_df.apply(pd.Series.nunique, axis=1)\n",
    "\n",
    "promotion_df = promotion_df.sort_values(by=['UID', 'EFFECTIVE DATE OF ACTION', 'total_finite_fields', 'total_distinct_fields'])\n",
    "promotion_df = promotion_df.drop_duplicates(subset=['UID', 'EFFECTIVE DATE OF ACTION'], keep='last')\n",
    "promotion_records = promotion_df.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This set of data has the following characteristics:\n",
    "1) Sometimes there are multiple promotions in the same quarter.\n",
    "2) Sometimes there are promotion events in consecutive quarters.\n",
    "3) Sometimes there are multiple events on the same day for the same person. As this is not realistically plausible, this is a technical data error that needs to be corrected.\n",
    "\n",
    "To circumvent these issues, the data is sorted by UID, date of action, number of finite fields, and number of distinct fields. Events that occurred on the same day are all dropped except for the event with the largest number of defined field, and the largest number of distinct fields if they all have the same number of defined fields.\n",
    "Data from the latest promotion event is then used to label the job titles and units of a given quarter. Old titles and units are used to fill in the information from last quarter, IFF there is no pre-existing data there. This in practice means that if there are multiple events per quarter:\n",
    "1) the last event (if multiple last events, the event with the largest # of finite and unique fields) determines titles of the current quarter)\n",
    "2) the first event (f multiple first events, the event with the largest # of finite and unique fields), given that no event occurred last quarter that was used to fill in its data) determines the titles of the past quarter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = promotion_df.columns.tolist()\n",
    "tenure_index = header.index('LENGTH OF SERVICE')\n",
    "hire_index = header.index('GROUP DOJ')\n",
    "action_index = header.index('ACTION CODE')\n",
    "# effective date of action is the same as start date for every record looked at\n",
    "quarter_index = header.index('EFFECTIVE DATE OF ACTION')\n",
    "reason_index = header.index('ACTION REASON')\n",
    "legal_index = header.index('NEW LEGAL ENTITY')\n",
    "title_index = header.index('NEW JOB TITLE')\n",
    "department_index = header.index('NEW DEPARTMENT')\n",
    "division_index = header.index('NEW DIVISION')\n",
    "function_index = header.index('NEW FUNCTION')\n",
    "bu_index = header.index('NEW BUSINESS UNIT NAME')\n",
    "city_index = header.index('NEW WORK CITY')\n",
    "state_index = header.index(\"NEW WORK STATE\")\n",
    "country_index = header.index(\"NEW WORK COUNTRY\")\n",
    "termination_date_index = header.index(\"TERMINATION DATE\")\n",
    "termination_reason_index = header.index(\"TERMINATION REASON\")\n",
    "\n",
    "for record in promotion_records:\n",
    "    uid = record[0]\n",
    "    quarter = date2quarter(record[quarter_index])\n",
    "\n",
    "    if (uid, quarter) in user_quarter2values:\n",
    "        user_quarter2values[(uid, quarter)][1] = calc_tenure(record[hire_index], quarter)\n",
    "        for i, index in enumerate([title_index, division_index, department_index, function_index,\n",
    "                                   city_index, state_index, country_index, legal_index], 2):\n",
    "            user_quarter2values[(uid, quarter)][i] = record[index]\n",
    "        prev_quarter = calc_prev_quarter(quarter)\n",
    "        \n",
    "        # use action reason as ground truth if available (actions are coded as promotion when they are specified as demotions or when \n",
    "        # titles are specified as lateral)\n",
    "        if type(record[reason_index]) == str:\n",
    "            # demotion and salary increase are mutually exclusive\n",
    "            if 'demotion' in record[reason_index].lower():\n",
    "                user_quarter2values[(uid, quarter)][long_header.index('demotion')] = 1\n",
    "            elif 'new salary' in record[reason_index].lower():\n",
    "                user_quarter2values[(uid, quarter)][long_header.index('salary_increase')] = 1\n",
    "            if 'promotion' in record[reason_index].lower():\n",
    "                user_quarter2values[(uid, quarter)][long_header.index('promotion')] = 1\n",
    "            # action codes seem to label someone as being promoted although action reason indicates that it is\n",
    "            # a lateral title change with a new salary; we are trying to exclude this case\n",
    "        elif 'promotion' in record[action_index].lower():\n",
    "            user_quarter2values[(uid, quarter)][long_header.index('promotion')] = 1\n",
    "\n",
    "    if (uid, prev_quarter) in user_quarter2values:\n",
    "        if np.isfinite(user_quarter2values[(uid, prev_quarter)][1]):\n",
    "            continue\n",
    "        for i, index in enumerate([title_index, division_index, department_index, function_index,\n",
    "                                   city_index, state_index, country_index, legal_index], 2):\n",
    "                user_quarter2values[(uid, prev_quarter)][i] = record[index-1]\n",
    "        user_quarter2values[(uid, prev_quarter)][1] = calc_tenure(record[hire_index], prev_quarter)\n",
    "           \n",
    "    if type(record[termination_date_index]) == str:\n",
    "        termination_quarter = date2quarter(record[termination_date_index])\n",
    "        if (uid, termination_quarter) in user_quarter2values:\n",
    "            user_quarter2values[(uid, termination_quarter)][long_header.index('exit')] = 1\n",
    "            user_quarter2values[(uid, termination_quarter)][long_header.index('exit_reason')] = record[termination_reason_index]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Transfer Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_df = pd.read_csv(transfer_path)\n",
    "transfer_df = transfer_df.drop(['PERSON ID', 'PERSON NUMBER', 'DOJ', \"LINK\"], axis=1)\n",
    "names = transfer_df.columns.tolist()\n",
    "transfer_df = transfer_df[['UID']+names[:-1]]\n",
    "transfer_df['total_finite_fields'] = transfer_df.count(axis=1)\n",
    "transfer_df['total_distinct_fields'] = transfer_df.apply(pd.Series.nunique, axis=1)\n",
    "transfer_df = transfer_df.sort_values(by=['UID', 'EFFECTIVE DATE OF ACTION', 'total_finite_fields', 'total_distinct_fields'])\n",
    "transfer_df = transfer_df.drop_duplicates(subset=['UID', 'EFFECTIVE DATE OF ACTION'], keep='last')\n",
    "transfer_records = transfer_df.values.tolist()\n",
    "# all indices remain the same between promotion and transfer data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transfer events are not as well formatted as the promotion events, and suffers more severely from the same issues. As a result, we prioritize records from the promotion data - if there are overlapping actions that take place in the same quarter, the data from the promotion data is used. Otherwise, it is processed in the same way as the promotion data.\n",
    "\n",
    "To circumvent these issues, the data is sorted by UID, date of action, number of finite fields, and number of distinct fields. Events that occurred on the same day are all dropped except for the event with the largest number of defined field, and the largest number of distinct fields if they all have the same number of defined fields.\n",
    "Data from the latest event is then used to label the job titles and units of a given quarter, IFF there is no data there (there might be data from promotion data). Old titles and units are used to fill in the information from last quarter, IFF there is no pre-existing data there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in transfer_records:\n",
    "    uid = record[0]\n",
    "    quarter = date2quarter(record[quarter_index])\n",
    "    if (uid, quarter) in user_quarter2values:\n",
    "        # Avoiding overwriting any previously existing records\n",
    "        if np.isfinite(user_quarter2values[(uid, quarter)][1]):\n",
    "            continue\n",
    "        user_quarter2values[(uid, quarter)][1] = calc_tenure(record[hire_index], quarter)\n",
    "        for i, index in enumerate([title_index, division_index, department_index, function_index,\n",
    "                                   city_index, state_index, country_index, legal_index], 2):\n",
    "            user_quarter2values[(uid, quarter)][i] = record[index]\n",
    "\n",
    "    prev_quarter = calc_prev_quarter(quarter)\n",
    "    if (uid, prev_quarter) in user_quarter2values:\n",
    "        if np.isfinite(user_quarter2values[(uid, prev_quarter)][1]):\n",
    "            continue\n",
    "        user_quarter2values[(uid, prev_quarter)][1] = calc_tenure(record[hire_index], prev_quarter)\n",
    "        for i, index in enumerate([title_index, division_index, department_index, function_index,\n",
    "                                   city_index, state_index, country_index, legal_index], 2):\n",
    "            user_quarter2values[(uid, prev_quarter)][i] = record[index-1]\n",
    "           \n",
    "    if type(record[termination_date_index]) == str:\n",
    "        termination_quarter = date2quarter(record[termination_date_index])\n",
    "        if (uid, termination_quarter) in user_quarter2values:\n",
    "            user_quarter2values[(uid, termination_quarter)][long_header.index('exit')] = 1\n",
    "            user_quarter2values[(uid, termination_quarter)][long_header.index('exit_reason')] = record[termination_reason_index]\n",
    "\n",
    "    # the action codes don't matter to us - all we care about is which unit the employee belonged to before and after"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Producing Longitudinal Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [],
   "source": [
    "mux = pd.MultiIndex.from_tuples(user_quarter2values.keys())\n",
    "long_hr = pd.DataFrame(list(user_quarter2values.values()), index=mux, columns=long_header)\n",
    "cols = ['job_title', 'division', 'department', 'function', 'work_location', 'work_state', 'work_country', 'legal_entity']\n",
    "long_hr.loc[:, cols] = long_hr.groupby(level=0)[cols].ffill()\n",
    "long_hr.loc[:, cols] = long_hr.groupby(level=0)[cols].bfill()\n",
    "long_hr = long_hr.sort_index()\n",
    "long_hr.index.names = ['uid', 'quarter']\n",
    "hire_dates = promotion_df.drop_duplicates(subset=['UID'])[['UID', 'GROUP DOJ']]\n",
    "hire_dates = hire_dates.append(transfer_df.drop_duplicates(subset=['UID'])[['UID', 'GROUP DOJ']])\n",
    "hire_dates = hire_dates.drop_duplicates()\n",
    "hire_dates = hire_dates.set_index('UID')\n",
    "hire_dates.index.name = 'uid'\n",
    "long_hr = long_hr.join(hire_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging Cross-Sectional HR Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_df = pd.read_csv(cs_hr_path)\n",
    "cs_df.columns = ['uid', 'legal_entity', 'DOJ', 'GROUP DOJ', 'tenure', 'job_title', 'business_unit', 'division', 'department', 'function', 'work_location', 'work_state', 'year_of_birth', 'gender', 'yva', 'link']\n",
    "cs_df = cs_df.drop(['yva', 'DOJ', 'link'], axis=1)\n",
    "cs_perf_df = pd.read_csv(cs_perf_hr_path)\n",
    "cs_perf_df.columns = ['uid', 'tenure', 'job_title', 'division', 'department', 'function', 'work_location', 'work_state', 'work_country', 'legal_entity', 'year_of_birth', 'gender', 'race', 'perf_2019', 'perf_2020', 'link']\n",
    "cs_perf_df = cs_perf_df.drop(['perf_2019', 'perf_2020', 'link'], axis=1)\n",
    "\n",
    "merged_cs_df = cs_df.merge(cs_perf_df, how='outer')\n",
    "merged_cs_df.iloc[649] = merged_cs_df.iloc[649].fillna(merged_cs_df.iloc[1734])\n",
    "# there is one duplicated row and the one that seems to be less useful is in row #1734, which we are dropping, after\n",
    "# we paste its useful values to the original row\n",
    "merged_cs_df = merged_cs_df.drop(1734)\n",
    "merged_cs_df = merged_cs_df.set_index('uid')\n",
    "merged_cs_df.index.name = 'uid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_hr = long_hr.combine_first(merged_cs_df)\n",
    "long_hr['tenure'] = long_hr.apply(lambda row : calc_tenure(row['GROUP DOJ'], row.name[1]) if type(row['GROUP DOJ']) == str else np.nan, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_hr.loc[long_hr['work_country'] == 'US', 'work_country'] = 'U.S.A.'\n",
    "long_hr.loc[long_hr['work_country'] == 'CA', 'work_country'] = 'Canada'\n",
    "long_hr.loc[long_hr['work_country'] == 'IN', 'work_country'] = 'India'\n",
    "long_hr.loc[long_hr['work_state'] == 'NC', 'work_state'] = 'North Carolina'\n",
    "long_hr['work_location'] = long_hr['work_location'].str.replace('\\(.+\\)', '').str.strip()\n",
    "long_hr.loc[long_hr['work_location'].str.contains('Bangalore'), 'work_location'] = 'Bangalore'\n",
    "long_hr.loc[long_hr['race'].isnull(), 'race'] = 'Missing'\n",
    "long_hr.loc[long_hr['race'].str.contains('Hispanic or Latino'), 'race'] = 'Hispanic or Latino'\n",
    "long_hr.loc[long_hr['race'] == 'Race missing or unknown', 'race'] = 'Missing'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging Performance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_likert_df = pd.read_csv(perf_rating_path)\n",
    "perf_percentage_df = pd.read_csv(perf_percentage_path)\n",
    "perf_likert_df = perf_likert_df[['UID', '2019 Perf_Type(Rating)', '2020 Perf_Type(Rating)']]\n",
    "perf_percentage_df = perf_percentage_df[['UID', '2019_Perf_Type(Percentage)', '2020_Perf_Type(Percentage)']]\n",
    "perf_likert_df.columns = [\"uid\", \"perf_rating_2019\", \"perf_rating_2020\"]\n",
    "perf_percentage_df.columns = [\"uid\", \"perf_percentage_2019\", \"perf_percentage_2020\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_likert_df = pd.melt(perf_likert_df, id_vars='uid', value_vars=['perf_rating_2019', 'perf_rating_2020'])\n",
    "perf_likert_df['year'] = perf_likert_df['variable'].apply(lambda var : 2019 if '2019' in var else 2020 if '2020' in var else np.nan)\n",
    "perf_likert_df.drop('variable', inplace=True, axis=1)\n",
    "perf_likert_df.columns = ['uid', 'perf_rating', 'year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_percentage_df = pd.melt(perf_percentage_df, id_vars='uid', value_vars=['perf_percentage_2019', 'perf_percentage_2020'])\n",
    "perf_percentage_df['year'] = perf_percentage_df['variable'].apply(lambda var : 2019 if '2019' in var else 2020 if '2020' in var else np.nan)\n",
    "perf_percentage_df.drop('variable', inplace=True, axis=1)\n",
    "perf_percentage_df.columns = ['uid', 'perf_percentage', 'year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_df = perf_percentage_df.append(perf_likert_df)\n",
    "perf_df = perf_df.set_index(['uid', 'year'])\n",
    "perf_df.loc[perf_df['perf_rating'] == 'Not Applicable', 'perf_rating'] = np.nan\n",
    "perf_df.loc[perf_df['perf_percentage'] == 'Not Applicable', 'perf_percentage'] = np.nan\n",
    "perf_df['perf_percentage'] = perf_df['perf_percentage'].str.replace(\"%\", \"\")\n",
    "perf_df['perf_percentage'] = perf_df['perf_percentage'].apply(lambda val: float(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_hr.to_csv(\"/Users/Lara/Documents/CompCulture/spacespace/COco/analyses_data/longitudinal_hr.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>legal_entity</th>\n",
       "      <th>GROUP DOJ</th>\n",
       "      <th>tenure</th>\n",
       "      <th>job_title</th>\n",
       "      <th>business_unit</th>\n",
       "      <th>division</th>\n",
       "      <th>department</th>\n",
       "      <th>function</th>\n",
       "      <th>work_location</th>\n",
       "      <th>work_state</th>\n",
       "      <th>year_of_birth</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U2</td>\n",
       "      <td>Collabera Inc.</td>\n",
       "      <td>16-Apr-96</td>\n",
       "      <td>24.36</td>\n",
       "      <td>Chief Information Officer</td>\n",
       "      <td>Corporate-Default (0Z)</td>\n",
       "      <td>Global Business Services</td>\n",
       "      <td>IT-Infrastructure</td>\n",
       "      <td>IT-Infrastructure</td>\n",
       "      <td>Basking Ridge (Allen Road)</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>1965</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U4</td>\n",
       "      <td>Collabera Inc.</td>\n",
       "      <td>2-Dec-96</td>\n",
       "      <td>23.73</td>\n",
       "      <td>Senior Payroll Manager</td>\n",
       "      <td>Corporate-Default (0Z)</td>\n",
       "      <td>Global Business Services</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Payroll</td>\n",
       "      <td>Basking Ridge (Allen Road)</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>1958</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U6</td>\n",
       "      <td>Collabera Inc.</td>\n",
       "      <td>12-Oct-98</td>\n",
       "      <td>21.87</td>\n",
       "      <td>Associate Vice President</td>\n",
       "      <td>Corporate-Default (0Z)</td>\n",
       "      <td>Global Business Services</td>\n",
       "      <td>Immigration</td>\n",
       "      <td>Immigration</td>\n",
       "      <td>Basking Ridge (Allen Road)</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>1967</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U7</td>\n",
       "      <td>Collabera Inc.</td>\n",
       "      <td>1-Feb-99</td>\n",
       "      <td>21.56</td>\n",
       "      <td>Executive Vice President</td>\n",
       "      <td>Ashwin-SAT Get (4A)</td>\n",
       "      <td>Strategic Accounts Team</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Basking Ridge (Allen Road)</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>1970</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U8</td>\n",
       "      <td>Collabera Inc.</td>\n",
       "      <td>31-Mar-99</td>\n",
       "      <td>21.40</td>\n",
       "      <td>Delivery Manager</td>\n",
       "      <td>Regional-Tyler (9C)</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Recruitment</td>\n",
       "      <td>Recruitment</td>\n",
       "      <td>Basking Ridge (Allen Road)</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>1971</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  uid    legal_entity  GROUP DOJ  tenure                  job_title  \\\n",
       "0  U2  Collabera Inc.  16-Apr-96   24.36  Chief Information Officer   \n",
       "1  U4  Collabera Inc.   2-Dec-96   23.73     Senior Payroll Manager   \n",
       "2  U6  Collabera Inc.  12-Oct-98   21.87   Associate Vice President   \n",
       "3  U7  Collabera Inc.   1-Feb-99   21.56   Executive Vice President   \n",
       "4  U8  Collabera Inc.  31-Mar-99   21.40           Delivery Manager   \n",
       "\n",
       "            business_unit                  division         department  \\\n",
       "0  Corporate-Default (0Z)  Global Business Services  IT-Infrastructure   \n",
       "1  Corporate-Default (0Z)  Global Business Services            Finance   \n",
       "2  Corporate-Default (0Z)  Global Business Services        Immigration   \n",
       "3     Ashwin-SAT Get (4A)   Strategic Accounts Team              Sales   \n",
       "4     Regional-Tyler (9C)                  Regional        Recruitment   \n",
       "\n",
       "            function               work_location  work_state  year_of_birth  \\\n",
       "0  IT-Infrastructure  Basking Ridge (Allen Road)  New Jersey           1965   \n",
       "1            Payroll  Basking Ridge (Allen Road)  New Jersey           1958   \n",
       "2        Immigration  Basking Ridge (Allen Road)  New Jersey           1967   \n",
       "3              Sales  Basking Ridge (Allen Road)  New Jersey           1970   \n",
       "4        Recruitment  Basking Ridge (Allen Road)  New Jersey           1971   \n",
       "\n",
       "   gender  \n",
       "0    Male  \n",
       "1  Female  \n",
       "2    Male  \n",
       "3    Male  \n",
       "4    Male  "
      ]
     },
     "execution_count": 743,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
